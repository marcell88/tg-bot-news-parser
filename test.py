# improved_embedding_test.py
import numpy as np
from sentence_transformers import SentenceTransformer
import logging
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from scipy.spatial.distance import jaccard, cityblock

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class AdvancedTextComparator:
    def __init__(self):
        self.model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'
        logging.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {self.model_name}")
        self.model = SentenceTransformer(self.model_name)
        logging.info("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    
    def normalize_vector(self, vec):
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä –∫ –µ–¥–∏–Ω–∏—á–Ω–æ–π –¥–ª–∏–Ω–µ"""
        norm = np.linalg.norm(vec)
        if norm == 0:
            return vec
        return vec / norm
    
    def cosine_similarity(self, vec1, vec2):
        """–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ)"""
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    
    def adjusted_cosine_similarity(self, vec1, vec2):
        """–°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –ø–æ—Ä–æ–≥–æ–º"""
        similarity = self.cosine_similarity(vec1, vec2)
        # –ü–æ–Ω–∏–∂–∞–µ–º –æ—Ü–µ–Ω–∫—É –¥–ª—è —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if similarity > 0.9:
            return 0.9 + (similarity - 0.9) * 0.1  # –°–∂–∏–º–∞–µ–º –≤–µ—Ä—Ö–Ω–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω
        return similarity
    
    def euclidean_similarity(self, vec1, vec2):
        """–ï–≤–∫–ª–∏–¥–æ–≤–æ —Å—Ö–æ–¥—Å—Ç–≤–æ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ)"""
        distance = np.linalg.norm(vec1 - vec2)
        return 1.0 / (1.0 + distance)
    
    def normalized_euclidean_similarity(self, vec1, vec2):
        """–ï–≤–∫–ª–∏–¥–æ–≤–æ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        vec1_norm = self.normalize_vector(vec1)
        vec2_norm = self.normalize_vector(vec2)
        distance = np.linalg.norm(vec1_norm - vec2_norm)
        return 1.0 - (distance / 2.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ [0, 1]
    
    def manhattan_similarity(self, vec1, vec2):
        """–ú–∞–Ω—Ö—ç—Ç—Ç–µ–Ω—Å–∫–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (L1 –Ω–æ—Ä–º–∞)"""
        distance = np.sum(np.abs(vec1 - vec2))
        return 1.0 / (1.0 + distance / len(vec1))  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    
    def dot_product_similarity(self, vec1, vec2):
        """–°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        vec1_norm = self.normalize_vector(vec1)
        vec2_norm = self.normalize_vector(vec2)
        return np.dot(vec1_norm, vec2_norm)
    
    def combined_similarity(self, vec1, vec2):
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ (—Å—Ä–µ–¥–Ω–µ–µ –∫–æ—Å–∏–Ω—É—Å–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –µ–≤–∫–ª–∏–¥–∞)"""
        cosine = self.adjusted_cosine_similarity(vec1, vec2)
        euclidean = self.normalized_euclidean_similarity(vec1, vec2)
        return (cosine + euclidean) / 2.0
    
    def analyze_similarity_pattern(self, text1, text2, vec1, vec2):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        diff = np.abs(vec1 - vec2)
        max_diff_indices = np.argsort(diff)[-5:]  # 5 —Å–∞–º—ã—Ö —Ä–∞–∑–Ω—ã—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π
        avg_diff = np.mean(diff)
        
        print(f"   –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π:")
        print(f"   - –°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞: {avg_diff:.4f}")
        print(f"   - –ú–∞–∫—Å —Ä–∞–∑–ª–∏—á–∏—è –≤ –∏–∑–º–µ—Ä–µ–Ω–∏—è—Ö: {max_diff_indices}")
        print(f"   - –î–ª–∏–Ω–∞ –≤–µ–∫—Ç–æ—Ä–∞ 1: {np.linalg.norm(vec1):.4f}")
        print(f"   - –î–ª–∏–Ω–∞ –≤–µ–∫—Ç–æ—Ä–∞ 2: {np.linalg.norm(vec2):.4f}")
    
    def compare_texts_comprehensive(self, text1, text2):
        """–í—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤"""
        print(f"\nüîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤:")
        print(f"   –¢–µ–∫—Å—Ç 1: '{text1}'")
        print(f"   –¢–µ–∫—Å—Ç 2: '{text2}'")
        
        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        embeddings = self.model.encode([text1, text2])
        vec1, vec2 = embeddings[0], embeddings[1]
        
        print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤: {vec1.shape}")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = {
            '–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ': self.cosine_similarity(vec1, vec2),
            '–°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ': self.adjusted_cosine_similarity(vec1, vec2),
            '–ï–≤–∫–ª–∏–¥–æ–≤–æ': self.euclidean_similarity(vec1, vec2),
            '–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –µ–≤–∫–ª–∏–¥–æ–≤–æ': self.normalized_euclidean_similarity(vec1, vec2),
            '–ú–∞–Ω—Ö—ç—Ç—Ç–µ–Ω—Å–∫–æ–µ': self.manhattan_similarity(vec1, vec2),
            '–°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ': self.dot_product_similarity(vec1, vec2),
            '–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ': self.combined_similarity(vec1, vec2)
        }
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π
        self.analyze_similarity_pattern(text1, text2, vec1, vec2)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\n   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:")
        for name, value in metrics.items():
            level = self._get_similarity_level(value)
            print(f"   - {name:<25}: {value:.4f} ({level})")
        
        return metrics, vec1, vec2
    
    def _get_similarity_level(self, similarity):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —Å—Ö–æ–∂–µ—Å—Ç–∏"""
        if similarity > 0.85:
            return "–û–ß–ï–ù–¨ –í–´–°–û–ö–ê–Ø üéØ"
        elif similarity > 0.7:
            return "–í–´–°–û–ö–ê–Ø ‚úÖ"
        elif similarity > 0.5:
            return "–°–†–ï–î–ù–Ø–Ø ‚ö†Ô∏è"
        elif similarity > 0.3:
            return "–ù–ò–ó–ö–ê–Ø üìâ"
        else:
            return "–û–ß–ï–ù–¨ –ù–ò–ó–ö–ê–Ø ‚ùå"
    
    def test_multiple_examples(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö"""
        examples = [
            ("–û–ø–ª–∞—Ç–∞ –∏—Å—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π Gripen", "–û–ø–ª–∞—Ç–∞ –∏—Å—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π"),
            ("–ü—É—Ç–∏–Ω –∏ –ó–µ–ª–µ–Ω—Å–∫–∏–π", "–ë–∞–π–¥–µ–Ω –∏ –¢—Ä–∞–º–ø"),
            ("–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞", "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"),
            ("–Ø–±–ª–æ–∫–∏ –∏ –∞–ø–µ–ª—å—Å–∏–Ω—ã", "–§—Ä—É–∫—Ç—ã –∏ –æ–≤–æ—â–∏"),
            ("–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è", "–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python")
        ]
        
        print("\n" + "="*70)
        print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –†–ê–ó–ù–´–• –ü–†–ò–ú–ï–†–ê–•")
        print("="*70)
        
        for text1, text2 in examples:
            print(f"\n–ü—Ä–∏–º–µ—Ä: '{text1}' vs '{text2}'")
            metrics, _, _ = self.compare_texts_comprehensive(text1, text2)
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
            best_metric = max(metrics.items(), key=lambda x: x[1])
            print(f"   üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–µ—Ç—Ä–∏–∫–∞: {best_metric[0]} ({best_metric[1]:.4f})")

def main():
    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    TEXT1 = "–≠–∫–æ–Ω–æ–º–∏–∫–∞"
    TEXT2 = "–ü–æ–ª–∏—Ç–∏–∫–∞"
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–∞—Ä–∞—Ç–æ—Ä–∞
    comparator = AdvancedTextComparator()
    
    print("="*70)
    print("–£–õ–£–ß–®–ï–ù–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –¢–ï–ö–°–¢–û–í –° –†–ê–ó–ù–´–ú–ò –ú–ï–¢–†–ò–ö–ê–ú–ò")
    print("="*70)
    
    # –û—Å–Ω–æ–≤–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    metrics, vec1, vec2 = comparator.compare_texts_comprehensive(TEXT1, TEXT2)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö
    comparator.test_multiple_examples()
    
    print("\n" + "="*70)
    print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("="*70)
    print("1. –î–ª—è –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤: '–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è' –∏–ª–∏ '–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –µ–≤–∫–ª–∏–¥–æ–≤–æ'")
    print("2. –î–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤: '–°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ'")
    print("3. –ò–∑–±–µ–≥–∞–π—Ç–µ —á–∏—Å—Ç–æ–≥–æ –∫–æ—Å–∏–Ω—É—Å–∞ –¥–ª—è –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤")
    print("4. '–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è' –º–µ—Ç—Ä–∏–∫–∞ - –Ω–∞–∏–±–æ–ª–µ–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è")

if __name__ == "__main__":
    main()